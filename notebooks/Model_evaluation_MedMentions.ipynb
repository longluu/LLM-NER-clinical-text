{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f1c2bf-26bd-4ef1-b70a-89c3096f121a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GatorTronS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbc7d5-156e-4cb6-96c8-99ae607d9ee8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc20b64-f3b8-405a-a1ef-a1377db9f40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "/home/ec2-user/SageMaker/LLM-NER-clinical-text/data/public/MedMentions/preprocessed-data/\n",
      "The device to run the model: cuda\n",
      "Load the pretrained model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of MegatronBertForTokenClassification were not initialized from the model checkpoint at UFNLP/gatortrons and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 354.262059millions parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2,635\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3,295\n",
      "  Number of trainable parameters = 354,262,059\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3295' max='3295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3295/3295 1:02:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.524100</td>\n",
       "      <td>0.416685</td>\n",
       "      <td>0.603839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.401952</td>\n",
       "      <td>0.627280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.429635</td>\n",
       "      <td>0.633531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.470514</td>\n",
       "      <td>0.633126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.103800</td>\n",
       "      <td>0.514751</td>\n",
       "      <td>0.633849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 878\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-659\n",
      "Configuration saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-659/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-659/model.safetensors\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-659/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-659/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 878\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1318\n",
      "Configuration saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1318/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1318/model.safetensors\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1318/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 878\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1977\n",
      "Configuration saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1977/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1977/model.safetensors\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1977/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-1977/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 878\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-2636\n",
      "Configuration saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-2636/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-2636/model.safetensors\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-2636/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-2636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 878\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-3295\n",
      "Configuration saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-3295/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-3295/model.safetensors\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-3295/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tmp-checkpoint-3295/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/checkpoint-1318 (score: 0.40195217728614807).\n",
      "Saving model checkpoint to /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/\n",
      "Configuration saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/model.safetensors\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.disable(logging.INFO) # disable INFO and DEBUG logging everywhere\n",
    "\n",
    "%run /home/ec2-user/SageMaker/LLM-NER-clinical-text/src/models/train_model.py \\\n",
    "--model_name 'UFNLP/gatortrons' \\\n",
    "--data_dir '/home/ec2-user/SageMaker/LLM-NER-clinical-text/data/public/MedMentions/preprocessed-data/' \\\n",
    "--batch_size 8 \\\n",
    "--num_train_epochs 5 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--weight_decay 0.01 \\\n",
    "--new_model_dir \"/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/\" \\\n",
    "--path_umls_semtype '/home/ec2-user/SageMaker/LLM-NER-clinical-text/data/public/MedMentions/SemGroups_2018.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea059678-d54a-4ed2-82dc-e0323354d8fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0794d8-5c85-4a96-87ab-2e19e1cf7b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "../data/public/MedMentions/preprocessed-data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.63101050849362,\n",
       " 'precision': 0.6714479559316552,\n",
       " 'recall': 0.6145681950682534,\n",
       " 'matthews_correlation': 0.7203455851532575}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.model import *\n",
    "\n",
    "# Load the model\n",
    "model_loader = ModelLoader('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/')\n",
    "\n",
    "# Evaluate the models on metrics\n",
    "scores = model_loader.evaluate_model(dataset_name='../data/public/MedMentions/preprocessed-data/',\\\n",
    "                                     path_umls_semtype='../data/public/MedMentions/SemGroups_2018.txt',\\\n",
    "                                     metric_names=['f1', 'precision', 'recall', 'matthews_correlation'])\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fdd3c-3fff-4ef4-847c-7c431d8e19ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fix the id2label in config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78a66135-7287-4517-9f26-741819060113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "../data/public/MedMentions/preprocessed-data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/longluu/Clinical-NER-MedMentions-GatorTronS/commit/357717279c7386e6e7b4d0203186085ed88d5a13', commit_message='fix the label2id in config', commit_description='', oid='357717279c7386e6e7b4d0203186085ed88d5a13', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from src.data.data_loader import *\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Load the config file\n",
    "f = open('../models/medmentions/gatortrons/config.json')\n",
    "config = json.load(f)\n",
    "\n",
    "# Load the dataset with label mapping\n",
    "dataset_loader = DatasetLoader(dataset_name='../data/public/MedMentions/preprocessed-data/', model_name='/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/', \\\n",
    "                               path_umls_semtype='../data/public/MedMentions/SemGroups_2018.txt')\n",
    "dataset, classmap, umls_label_code, _ = dataset_loader.load_dataset()\n",
    "\n",
    "# Add the label to the config\n",
    "id_to_tag = {ind: classmap.int2str(ind) for ind in range(len(classmap.names))}\n",
    "id_to_label = {ind: str(umls_label_code[id_to_tag[ind]]) for ind in range(len(classmap.names))}\n",
    "config['id2label'] = id_to_label\n",
    "config['label2id'] = {id_to_label[key]: key for key in id_to_label.keys()}\n",
    "# Save the config\n",
    "with open('../models/medmentions/gatortrons/config.json', 'w') as f:\n",
    "    json.dump(config, f)\n",
    "    \n",
    "# Push the config to hub\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"../models/medmentions/gatortrons/config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=\"longluu/Clinical-NER-MedMentions-GatorTronS\",\n",
    "    repo_type=\"model\",\n",
    "    commit_message=\"fix the label2id in config\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce48269-eef3-4c41-bdb3-4382ef083cba",
   "metadata": {},
   "source": [
    "## Push to model to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3735a05b-0e15-4a21-be93-3761629c6753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fad5ef434d405fa68456d87d1c7df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a995cd00-d5fa-40bb-a211-cb56e6406e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "README.md: 100%|██████████| 21.0/21.0 [00:00<00:00, 3.65kB/s]\n",
      "model.safetensors: 100%|██████████| 1.42G/1.42G [00:34<00:00, 41.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/longluu/Clinical-NER-MedMentions-GatorTronS/commit/e6a951cf15bd341dacaf6c242100e784c7f0dee3', commit_message='--batch_size 4 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01', commit_description='', oid='e6a951cf15bd341dacaf6c242100e784c7f0dee3', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer\n",
    "\n",
    "# Push the model to hub\n",
    "NER_model.push_to_hub(\"longluu/Clinical-NER-MedMentions-GatorTronS\", commit_message='--batch_size 4 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01')\n",
    "tokenizer.push_to_hub(\"longluu/Clinical-NER-MedMentions-GatorTronS\", commit_message='--batch_size 4 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4a1d1-1aff-4960-adc1-020763075f74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GatorTron-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b142ec-5299-4c7b-b542-fb11f221e020",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86f9035-7155-4c45-917e-7eeac23f9a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "/home/ec2-user/SageMaker/LLM-NER-clinical-text/data/public/MedMentions/preprocessed-data/\n",
      "The device to run the model: cuda\n",
      "Load the pretrained model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of MegatronBertForTokenClassification were not initialized from the model checkpoint at UFNLP/gatortron-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 354.262059millions parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3295' max='3295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3295/3295 1:02:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.427210</td>\n",
       "      <td>0.595944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.411381</td>\n",
       "      <td>0.619327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.425950</td>\n",
       "      <td>0.626551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.460033</td>\n",
       "      <td>0.628520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.497196</td>\n",
       "      <td>0.629384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "logging.disable(logging.INFO) # disable INFO and DEBUG logging everywhere\n",
    "\n",
    "%run /home/ec2-user/SageMaker/LLM-NER-clinical-text/src/models/train_model.py \\\n",
    "--model_name 'UFNLP/gatortron-base' \\\n",
    "--data_dir '/home/ec2-user/SageMaker/LLM-NER-clinical-text/data/public/MedMentions/preprocessed-data/' \\\n",
    "--batch_size 4 \\\n",
    "--num_train_epochs 5 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--weight_decay 0.01 \\\n",
    "--new_model_dir \"/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortron-base/\" \\\n",
    "--path_umls_semtype '/home/ec2-user/SageMaker/LLM-NER-clinical-text/data/public/MedMentions/SemGroups_2018.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8a0ca-572b-4396-a7d5-807cc2564de7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ffbd5be-a629-4d7e-8c81-923671bccb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "../data/public/MedMentions/preprocessed-data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n",
      "Generating train split: 2635 examples [00:00, 10628.05 examples/s]\n",
      "Generating validation split: 0 examples [00:00, ? examples/s]/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n",
      "Generating validation split: 878 examples [00:00, 10999.40 examples/s]\n",
      "Generating test split: 0 examples [00:00, ? examples/s]/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n",
      "Generating test split: 879 examples [00:00, 11690.08 examples/s]\n",
      "Map: 100%|██████████| 2635/2635 [00:00<00:00, 5323.67 examples/s]\n",
      "Map: 100%|██████████| 878/878 [00:00<00:00, 5257.69 examples/s]\n",
      "Map: 100%|██████████| 879/879 [00:00<00:00, 5237.67 examples/s]\n",
      "Map: 100%|██████████| 2635/2635 [00:01<00:00, 2350.81 examples/s]\n",
      "Map: 100%|██████████| 878/878 [00:00<00:00, 2361.32 examples/s]\n",
      "Map: 100%|██████████| 879/879 [00:00<00:00, 2357.71 examples/s]\n",
      "Map: 100%|██████████| 2635/2635 [00:02<00:00, 1011.36 examples/s]\n",
      "Map: 100%|██████████| 878/878 [00:00<00:00, 1005.51 examples/s]\n",
      "Map: 100%|██████████| 879/879 [00:00<00:00, 1014.24 examples/s]\n",
      "Map: 100%|██████████| 879/879 [00:59<00:00, 14.75 examples/s]\n",
      "Downloading builder script: 100%|██████████| 6.77k/6.77k [00:00<00:00, 14.9MB/s]\n",
      "Downloading builder script: 100%|██████████| 7.55k/7.55k [00:00<00:00, 15.0MB/s]\n",
      "Downloading builder script: 100%|██████████| 7.36k/7.36k [00:00<00:00, 14.8MB/s]\n",
      "Downloading builder script: 100%|██████████| 6.60k/6.60k [00:00<00:00, 13.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6271402249699903,\n",
       " 'precision': 0.6691625224055963,\n",
       " 'recall': 0.6085333637974402,\n",
       " 'matthews_correlation': 0.720898121696139}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.model import *\n",
    "\n",
    "# Load the model\n",
    "model_loader = ModelLoader('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortron-base/')\n",
    "\n",
    "# Evaluate the models on metrics\n",
    "scores = model_loader.evaluate_model(dataset_name='../data/public/MedMentions/preprocessed-data/',\\\n",
    "                                     path_umls_semtype='../data/public/MedMentions/SemGroups_2018.txt',\\\n",
    "                                     metric_names=['f1', 'precision', 'recall', 'matthews_correlation'])\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc5fbb-43e7-409a-a603-3db63d2cfcd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fix the id2label in config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb78244f-9ed1-4cde-b3a8-750feb4db7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "../data/public/MedMentions/preprocessed-data/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from src.data.data_loader import *\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Load the config file\n",
    "f = open('../models/medmentions/gatortrons/config.json')\n",
    "config = json.load(f)\n",
    "\n",
    "# Load the dataset with label mapping\n",
    "dataset_loader = DatasetLoader(dataset_name='../data/public/MedMentions/preprocessed-data/', model_name='/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortrons/', \\\n",
    "                               path_umls_semtype='../data/public/MedMentions/SemGroups_2018.txt')\n",
    "dataset, classmap, umls_label_code, _ = dataset_loader.load_dataset()\n",
    "\n",
    "# Add the label to the config\n",
    "id_to_tag = {ind: classmap.int2str(ind) for ind in range(len(classmap.names))}\n",
    "id_to_label = {ind: str(umls_label_code[id_to_tag[ind]]) for ind in range(len(classmap.names))}\n",
    "config['id2label'] = id_to_label\n",
    "config['label2id'] = {id_to_label[key]: key for key in id_to_label.keys()}\n",
    "# Save the config\n",
    "with open('../models/medmentions/gatortron-base/config.json', 'w') as f:\n",
    "    json.dump(config, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a53ee7-7d44-4c8c-b1dc-5ea654ebba9a",
   "metadata": {},
   "source": [
    "## Push to model to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d028a9e4-9c5e-4da8-844a-042dd83dc12e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fad5ef434d405fa68456d87d1c7df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "007438cd-a28b-49ec-8ab5-515035ffe759",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "README.md: 100%|██████████| 21.0/21.0 [00:00<00:00, 3.52kB/s]\n",
      "model.safetensors: 100%|██████████| 1.42G/1.42G [00:34<00:00, 41.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/longluu/Clinical-NER-MedMentions-GatorTronBase/commit/0d3d619bf64c19649f358ab0688c26e22c51edfa', commit_message='--batch_size 4 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01', commit_description='', oid='0d3d619bf64c19649f358ab0688c26e22c51edfa', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer\n",
    "\n",
    "# Load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortron-base/')\n",
    "NER_model = AutoModelForTokenClassification.from_pretrained('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/medmentions/gatortron-base/')\n",
    "                                                            \n",
    "# Push the model to hub\n",
    "NER_model.push_to_hub(\"longluu/Clinical-NER-MedMentions-GatorTronBase\", commit_message='--batch_size 4 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01')\n",
    "tokenizer.push_to_hub(\"longluu/Clinical-NER-MedMentions-GatorTronBase\", commit_message='--batch_size 4 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f3dfe-c15b-4b7d-a3dc-5fc1717f0f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (Tutorial-LLM)",
   "language": "python",
   "name": "tutorial-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
