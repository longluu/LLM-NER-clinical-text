{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f1c2bf-26bd-4ef1-b70a-89c3096f121a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GatorTronS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbc7d5-156e-4cb6-96c8-99ae607d9ee8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc20b64-f3b8-405a-a1ef-a1377db9f40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "ncbi_disease\n",
      "The device to run the model: cuda\n",
      "Load the pretrained model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of MegatronBertForTokenClassification were not initialized from the model checkpoint at UFNLP/gatortrons and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 354.221059millions parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1135' max='1135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1135/1135 17:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.039396</td>\n",
       "      <td>0.871549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.047854</td>\n",
       "      <td>0.865149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.053422</td>\n",
       "      <td>0.875276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.061332</td>\n",
       "      <td>0.876097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.073064</td>\n",
       "      <td>0.880380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no-disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease-continue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no-disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease-continue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no-disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease-continue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no-disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease-continue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no-disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: disease-continue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.disable(logging.INFO) # disable INFO and DEBUG logging everywhere\n",
    "\n",
    "%run /home/ec2-user/SageMaker/LLM-NER-clinical-text/src/models/train_model.py \\\n",
    "--model_name 'UFNLP/gatortrons' \\\n",
    "--data_dir 'ncbi_disease' \\\n",
    "--batch_size 24 \\\n",
    "--num_train_epochs 5 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--weight_decay 0.01 \\\n",
    "--new_model_dir \"/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/\" \\\n",
    "--path_umls_semtype '/home/ec2-user/SageMaker/LLM-NER-clinical-text/data/public/MedMentions/SemGroups_2018.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea059678-d54a-4ed2-82dc-e0323354d8fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0794d8-5c85-4a96-87ab-2e19e1cf7b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "ncbi_disease\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9765d495c3473392f500f80c4ba693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9230959441861525,\n",
       " 'precision': 0.8998375309216448,\n",
       " 'recall': 0.948772382840148,\n",
       " 'matthews_correlation': 0.8978492834665438}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.model import *\n",
    "\n",
    "# Load the model\n",
    "model_loader = ModelLoader('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/')\n",
    "\n",
    "# Evaluate the models on metrics\n",
    "scores = model_loader.evaluate_model(dataset_name='ncbi_disease',\\\n",
    "                                     path_umls_semtype='../data/public/MedMentions/SemGroups_2018.txt',\\\n",
    "                                     metric_names=['f1', 'precision', 'recall', 'matthews_correlation'])\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fdd3c-3fff-4ef4-847c-7c431d8e19ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fix the id2label in config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a66135-7287-4517-9f26-741819060113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "ncbi_disease\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from src.data.data_loader import *\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Load the config file\n",
    "f = open('../models/ncbi-disease/gatortrons/config.json')\n",
    "config = json.load(f)\n",
    "\n",
    "# Load the dataset with label mapping\n",
    "dataset_loader = DatasetLoader(dataset_name='ncbi_disease', model_name='/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/', \\\n",
    "                               path_umls_semtype='../data/public/MedMentions/SemGroups_2018.txt')\n",
    "dataset, classmap, umls_label_code, _ = dataset_loader.load_dataset()\n",
    "\n",
    "# Add the label to the config\n",
    "id_to_label = {ind: classmap.int2str(ind) for ind in range(len(classmap.names))}\n",
    "config['id2label'] = id_to_label\n",
    "config['label2id'] = {id_to_label[key]: key for key in id_to_label.keys()}\n",
    "\n",
    "# Save the config\n",
    "with open('../models/ncbi-disease/gatortrons/config.json', 'w') as f:\n",
    "    json.dump(config, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fd5283-1b29-4b00-b4af-6c3e9c5d90d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/longluu/Clinical-NER-NCBI-Disease-GatorTronS/commit/f87294d962ac365cc8d9c3fb4b7884d44a6bcbb3', commit_message='fix the label2id in config', commit_description='', oid='f87294d962ac365cc8d9c3fb4b7884d44a6bcbb3', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the config to hub\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"../models/ncbi-disease/gatortrons/config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=\"longluu/Clinical-NER-NCBI-Disease-GatorTronS\",\n",
    "    repo_type=\"model\",\n",
    "    commit_message=\"fix the label2id in config\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce48269-eef3-4c41-bdb3-4382ef083cba",
   "metadata": {},
   "source": [
    "## Push to model to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3735a05b-0e15-4a21-be93-3761629c6753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef3efe0ae4b44c6b6ff280d77a74773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a995cd00-d5fa-40bb-a211-cb56e6406e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a16a9ba5bbc4645977d6336c742c5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6adddaccb74459a8ef8e0fb9125b0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/longluu/Clinical-NER-NCBI-Disease-GatorTronS/commit/83f96f0b04875ccf18c2a5a80064218eeb61570a', commit_message='--batch_size 24 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01', commit_description='', oid='83f96f0b04875ccf18c2a5a80064218eeb61570a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer\n",
    "\n",
    "# Load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/')\n",
    "NER_model = AutoModelForTokenClassification.from_pretrained('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/')\n",
    "\n",
    "# Push the model to hub\n",
    "NER_model.push_to_hub(\"longluu/Clinical-NER-NCBI-Disease-GatorTronS\", commit_message='--batch_size 24 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01')\n",
    "tokenizer.push_to_hub(\"longluu/Clinical-NER-NCBI-Disease-GatorTronS\", commit_message='--batch_size 24 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a433eff-8ea7-4337-9a9e-bad92cd38fdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5950dc6a-9ee0-4124-b3f0-0eb6e8de13e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4b247a80024f84875490dc486f9df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f68790c466548179c24a22d86501d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/379k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4388e2abdf124ce9a015a726b6a87a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bede44324b4a18a845cf2cdc25924a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "ncbi_disease\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e20ae4314d463ba709e6d5c495043d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac3e1ecfe954f4a8a9fa354a5a872fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/924 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a301a055ce34362aeb8cdff740cafc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device to run the model: cuda\n",
      "Load the pretrained model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d2c93e112441e7bdbb0525cdfb1a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2e7e4837114375a3628926f82b6564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MegatronBertForTokenClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([43, 1024]) from checkpoint, the shape in current model is torch.Size([3, 1024]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([3]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/SageMaker/LLM-NER-clinical-text/src/models/train_model.py:137\u001b[0m\n\u001b[1;32m    134\u001b[0m     model_trainer\u001b[38;5;241m.\u001b[39mtrain_model()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SageMaker/LLM-NER-clinical-text/src/models/train_model.py:134\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m model_trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(dataset_name\u001b[38;5;241m=\u001b[39mglobal_args\u001b[38;5;241m.\u001b[39mdata_dir,\n\u001b[1;32m    125\u001b[0m                              path_umls_semtype\u001b[38;5;241m=\u001b[39mglobal_args\u001b[38;5;241m.\u001b[39mpath_umls_semtype,\n\u001b[1;32m    126\u001b[0m                              model_name\u001b[38;5;241m=\u001b[39mglobal_args\u001b[38;5;241m.\u001b[39mmodel_name, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m                              weight_decay\u001b[38;5;241m=\u001b[39mglobal_args\u001b[38;5;241m.\u001b[39mweight_decay,\n\u001b[1;32m    131\u001b[0m                              learning_rate\u001b[38;5;241m=\u001b[39mglobal_args\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SageMaker/LLM-NER-clinical-text/src/models/train_model.py:36\u001b[0m, in \u001b[0;36mModelTrainer.train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Create an NER model from a base pretrained model\u001b[39;00m\n\u001b[1;32m     35\u001b[0m model_loader \u001b[38;5;241m=\u001b[39m ModelLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name)\n\u001b[0;32m---> 36\u001b[0m NER_model, tokenizer, config \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclassmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Create a collator\u001b[39;00m\n\u001b[1;32m     39\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForTokenClassification(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[0;32m~/SageMaker/LLM-NER-clinical-text/src/models/model.py:25\u001b[0m, in \u001b[0;36mModelLoader.load_model\u001b[0;34m(self, num_labels)\u001b[0m\n\u001b[1;32m     23\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name)\n\u001b[1;32m     24\u001b[0m config\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m=\u001b[39m num_labels\n\u001b[0;32m---> 25\u001b[0m NER_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForTokenClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe model has \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(NER_model\u001b[38;5;241m.\u001b[39mnum_parameters()\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e6\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmillions parameters.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m NER_model, tokenizer, config\n",
      "File \u001b[0;32m~/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/transformers/modeling_utils.py:3852\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3843\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3844\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3845\u001b[0m     (\n\u001b[1;32m   3846\u001b[0m         model,\n\u001b[1;32m   3847\u001b[0m         missing_keys,\n\u001b[1;32m   3848\u001b[0m         unexpected_keys,\n\u001b[1;32m   3849\u001b[0m         mismatched_keys,\n\u001b[1;32m   3850\u001b[0m         offload_index,\n\u001b[1;32m   3851\u001b[0m         error_msgs,\n\u001b[0;32m-> 3852\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3859\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3860\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3863\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3864\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3868\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3870\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3871\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/SageMaker/custom-miniconda/miniconda/envs/Tutorial-LLM/lib/python3.9/site-packages/transformers/modeling_utils.py:4337\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   4333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_msg:\n\u001b[1;32m   4334\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4336\u001b[0m         )\n\u001b[0;32m-> 4337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unexpected_keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   4340\u001b[0m     archs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39marchitectures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39marchitectures\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MegatronBertForTokenClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([43, 1024]) from checkpoint, the shape in current model is torch.Size([3, 1024]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([3]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.disable(logging.INFO) # disable INFO and DEBUG logging everywhere\n",
    "\n",
    "%run /home/ec2-user/SageMaker/LLM-NER-clinical-text/src/models/train_model.py \\\n",
    "--model_name 'longluu/Clinical-NER-MedMentions-GatorTronS' \\\n",
    "--data_dir 'ncbi_disease' \\\n",
    "--batch_size 24 \\\n",
    "--num_train_epochs 5 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--weight_decay 0.01 \\\n",
    "--new_model_dir \"/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons-medmentions/\" \\\n",
    "--path_umls_semtype '/home/ec2-user/SageMaker/LLM-NER-clinical-text/data/public/MedMentions/SemGroups_2018.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2341884-9ade-4589-9f6d-b92ad17edc84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf3b60d-5131-44c2-b18e-f55b59f642e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "ncbi_disease\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9765d495c3473392f500f80c4ba693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9230959441861525,\n",
       " 'precision': 0.8998375309216448,\n",
       " 'recall': 0.948772382840148,\n",
       " 'matthews_correlation': 0.8978492834665438}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.model import *\n",
    "\n",
    "# Load the model\n",
    "model_loader = ModelLoader('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/')\n",
    "\n",
    "# Evaluate the models on metrics\n",
    "scores = model_loader.evaluate_model(dataset_name='ncbi_disease',\\\n",
    "                                     path_umls_semtype='../data/public/MedMentions/SemGroups_2018.txt',\\\n",
    "                                     metric_names=['f1', 'precision', 'recall', 'matthews_correlation'])\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc2c04-6898-4495-8cf8-3f0d29d89de2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fix the id2label in config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03973f1d-a572-416e-a469-0f32eace0e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dataset ...\n",
      "ncbi_disease\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from src.data.data_loader import *\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Load the config file\n",
    "f = open('../models/ncbi-disease/gatortrons/config.json')\n",
    "config = json.load(f)\n",
    "\n",
    "# Load the dataset with label mapping\n",
    "dataset_loader = DatasetLoader(dataset_name='ncbi_disease', model_name='/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/', \\\n",
    "                               path_umls_semtype='../data/public/MedMentions/SemGroups_2018.txt')\n",
    "dataset, classmap, umls_label_code, _ = dataset_loader.load_dataset()\n",
    "\n",
    "# Add the label to the config\n",
    "id_to_label = {ind: classmap.int2str(ind) for ind in range(len(classmap.names))}\n",
    "config['id2label'] = id_to_label\n",
    "config['label2id'] = {id_to_label[key]: key for key in id_to_label.keys()}\n",
    "\n",
    "# Save the config\n",
    "with open('../models/ncbi-disease/gatortrons/config.json', 'w') as f:\n",
    "    json.dump(config, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58bd25-db14-42d8-bcf7-9bfc30055ac9",
   "metadata": {},
   "source": [
    "## Push to model to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485d59b8-df91-43c5-a2b5-f3ed0b4bfa16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef3efe0ae4b44c6b6ff280d77a74773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d809382-a6f9-468b-95f5-1e1d5e8e3053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a16a9ba5bbc4645977d6336c742c5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6adddaccb74459a8ef8e0fb9125b0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/longluu/Clinical-NER-NCBI-Disease-GatorTronS/commit/83f96f0b04875ccf18c2a5a80064218eeb61570a', commit_message='--batch_size 24 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01', commit_description='', oid='83f96f0b04875ccf18c2a5a80064218eeb61570a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer\n",
    "\n",
    "# Load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/')\n",
    "NER_model = AutoModelForTokenClassification.from_pretrained('/home/ec2-user/SageMaker/LLM-NER-clinical-text/models/ncbi-disease/gatortrons/')\n",
    "\n",
    "# Push the model to hub\n",
    "NER_model.push_to_hub(\"longluu/Clinical-NER-NCBI-Disease-GatorTronS\", commit_message='--batch_size 24 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01')\n",
    "tokenizer.push_to_hub(\"longluu/Clinical-NER-NCBI-Disease-GatorTronS\", commit_message='--batch_size 24 --num_train_epochs 5 --learning_rate 5e-5 --weight_decay 0.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f3dfe-c15b-4b7d-a3dc-5fc1717f0f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (Tutorial-LLM)",
   "language": "python",
   "name": "tutorial-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
